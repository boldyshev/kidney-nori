{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "ROOT_PATH = Path.cwd().parent\n",
    "sys.path.append(str(ROOT_PATH))\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize_config_dir, compose\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.data.dataset import Nuclei\n",
    "from src.models.unet import UNet\n",
    "from src.utils.dice import dice_loss, dice_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = str(ROOT_PATH / 'conf')\n",
    "with initialize_config_dir(version_base=None, config_dir=config_dir):\n",
    "    cfg = compose(config_name='config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=(0, 360)),\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "val_tfms = v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "CHECKPOINTS_PATH = ROOT_PATH / cfg.paths.checkpoints\n",
    "DATA_DIR = ROOT_PATH / cfg.paths.train_data\n",
    "VAL_PERCENT = 0.2\n",
    "cfg.batch_size = 1\n",
    "\n",
    "train_files = ['Fused_S1_1.tif']\n",
    "image_paths = [str(DATA_DIR / img_file) for img_file in train_files]\n",
    "dataset =  Nuclei(image_paths, transforms=train_tfms)\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=cfg.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=cfg.batch_size, shuffle=True, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = UNet(1, 1)\n",
    "model.to(cfg.device)\n",
    "optimizer = instantiate(cfg.optimizer, params=model.parameters())\n",
    "criterion = instantiate(cfg.loss)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-4, total_steps=cfg.epochs * n_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    num_val_batches = len(dataloader)\n",
    "    dice_score = 0\n",
    "\n",
    "    # iterate over the validation set\n",
    "    for imgs, masks in dataloader:\n",
    "        images, true_masks = imgs.to(device), masks.to(device)\n",
    "        with torch.no_grad():\n",
    "            masks_pred = model(images)\n",
    "\n",
    "            # predict the mask\n",
    "            mask_pred = model(images)\n",
    "\n",
    "            assert true_masks.min() >= 0 and true_masks.max() <= 1, 'True mask indices should be in [0, 1]'\n",
    "            mask_pred = (F.sigmoid(mask_pred) > 0.5).float()\n",
    "            # compute the Dice score\n",
    "            dice_score += dice_coeff(mask_pred, true_masks, reduce_batch_first=False)\n",
    "\n",
    "    return dice_score / max(len(dataloader), 1)\n",
    "\n",
    "def save_checkpoint(model, epoch):\n",
    "    state_dict = model.state_dict()\n",
    "    epoch = str(epoch)\n",
    "    epoch_num =  '0' * (3 - len(epoch)) + epoch\n",
    "    checkpoint_path = str(CHECKPOINTS_PATH / f'epoch{epoch_num}.pth')\n",
    "    torch.save(state_dict, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, cfg.epochs + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    pbar = tqdm(total=n_train, desc=f'Epoch {epoch}')\n",
    "    for imgs, masks in train_loader:\n",
    "        images, true_masks = imgs.to(device), masks.to(device)\n",
    "        masks_pred = model(images)\n",
    "\n",
    "        batch_loss = criterion(masks_pred.squeeze(1), true_masks.squeeze(1))\n",
    "        masks_pred_dice = F.sigmoid(masks_pred.squeeze(1))\n",
    "        batch_loss += dice_loss(masks_pred_dice, true_masks.squeeze(1), multiclass=False)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += batch_loss.item()\n",
    "        \n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix(**{'loss': f'{batch_loss.item():.4f}'})\n",
    "\n",
    "    avg_batch_loss = epoch_loss / n_train\n",
    "    pbar.set_postfix(**{'loss': f'{avg_batch_loss:.4f}'})\n",
    "    pbar.close()\n",
    "    \n",
    "    # Validate and save scheckpoint\n",
    "    val_score = evaluate(model, val_loader, device).item()\n",
    "    print(f'Validation Dice score: {val_score}')\n",
    "    save_checkpoint(model, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
